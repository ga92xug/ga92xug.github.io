---
layout: page
title: Multimodal Interview Assessment
description: Lab Course Explainable AI for Machine Learning with Siemens
img: assets/img/interview_facial_action_units.png
importance: 5
category: University
---
<!-- Thesis image and description -->
<div class="row justify-content-center">
    <div class="col-auto">
        {% include figure.html path="assets/img/dashboard_interview.png" alt="Interview_dashboard" class="img-fluid rounded z-depth-1"%}
    </div>
</div>
<!-- Download buttons -->
<div class="row mt-4 justify-content-center">
    <div class=".col-sm">
        <a href="/assets/pdf/XAI_final_report.pdf" class="btn btn-primary">
            <i class="fa fa-download"></i> Paper
        </a>
    </div>
    <div class=".col-sm">
        <a href="/assets/pdf/Final_presentation_XAI.pdf" class="btn btn-primary">
            <i class="fa fa-download"></i> Presentation
        </a>
    </div>
</div>

# Abstract
In a job interview setting, personality traits, behavioral cues and soft skills are evaluated alongside the experience and hard skills. It is therefore important for potential interviewees to be aware of his/her positive and negative attributes. This paper provides a multi-modal approach to assess and give feedback for an interviewee, based on his/her performance in an interview simulation. We extract prosodic, textual, and facial features and train machine learning models to predict relevant labels such as emotions and fluency and analyze the association between these labels and the quality of an interview. Explainability techniques such as LIME are used to highlight the most prominent features and thereby make the system more understandable for the end user.

<!-- Thesis image and description -->
<div class="row justify-content-center">
    <div class="col-auto">
        {% include figure.html path="assets/img/interview_facial_action_units.png" alt="Interview_dashboard" class="img-fluid rounded z-depth-1" width="300" height="300"%}
    </div>
</div>